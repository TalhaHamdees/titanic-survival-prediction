{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "# Titanic Dataset — End-to-End ML Pipeline\n",
    "\n",
    "## Evolution from Notebook 02\n",
    "In the previous notebook, we built preprocessing and the model as **separate steps** — calling `preprocessor.fit_transform()`, then `model.fit()`, then `model.predict()` individually. This approach works, but requires manually managing the preprocessing and model as separate objects, which is error-prone and harder to maintain.\n",
    "\n",
    "Here, we combine everything into a **single scikit-learn Pipeline** — one object that goes from raw features straight to predictions.\n",
    "\n",
    "## Why Pipelines Matter\n",
    "- **Prevents data leakage** — the pipeline ensures `fit` only happens on training data, by design\n",
    "- **Cleaner code** — one `fit()` call, one `predict()` call, no intermediate variables\n",
    "- **Production-ready** — you can save this single pipeline object and deploy it directly\n",
    "- **Industry standard** — this is how ML workflows are built in professional environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-header",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-header",
   "metadata": {},
   "source": [
    "## 2. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-features",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
      "X shape: (891, 7), y shape: (891,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target\n",
    "y = df['Survived']\n",
    "\n",
    "# Features — drop target + non-useful columns in one step\n",
    "X = df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-header",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (712, 7)\n",
      "Test set:     (179, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set:     {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-header",
   "metadata": {},
   "source": [
    "## 4. Build the End-to-End Pipeline\n",
    "\n",
    "This is the key upgrade. Instead of separate preprocessing and model steps, we create **one Pipeline** that chains:\n",
    "\n",
    "1. **Preprocessor** (ColumnTransformer) — handles imputation and encoding\n",
    "2. **Model** (Logistic Regression) — learns from the preprocessed data\n",
    "\n",
    "When we call `pipeline.fit(X_train, y_train)`, it automatically:\n",
    "- Fits the preprocessor on `X_train` and transforms it\n",
    "- Fits the model on the transformed result\n",
    "\n",
    "When we call `pipeline.predict(X_test)`, it automatically:\n",
    "- Transforms `X_test` using the already-fitted preprocessor\n",
    "- Predicts using the already-fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-column-types",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column types\n",
    "numeric_cols = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\n",
    "categorical_cols = ['Sex', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created:\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  SimpleImputer(strategy='median'),\n",
      "                                                  ['Age', 'SibSp', 'Parch',\n",
      "                                                   'Fare', 'Pclass']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(drop='first',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['Sex', 'Embarked'])])),\n",
      "                ('model', LogisticRegression(max_iter=1000))])\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing step (same logic as notebook 02)\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', SimpleImputer(strategy='median'), numeric_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# End-to-end pipeline: preprocessing + model in one object\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "print(\"Pipeline created:\")\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-header",
   "metadata": {},
   "source": [
    "## 5. Train and Predict\n",
    "\n",
    "Notice how clean this is — **two lines** to go from raw data to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-train-predict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline trained and predictions generated!\n",
      "Predictions shape: (179,)\n",
      "Probabilities shape: (179, 2)\n"
     ]
    }
   ],
   "source": [
    "# Train: preprocesses + fits the model in one call\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict: preprocesses + predicts in one call\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "print(\"Pipeline trained and predictions generated!\")\n",
    "print(f\"Predictions shape: {y_pred.shape}\")\n",
    "print(f\"Probabilities shape: {y_pred_proba.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-header",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8045 (80.45%)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98 12]\n",
      " [23 46]]\n",
      "\n",
      "  - True Negatives  (correctly predicted died):          98\n",
      "  - False Positives (predicted survived, actually died): 12\n",
      "  - False Negatives (predicted died, actually survived): 23\n",
      "  - True Positives  (correctly predicted survived):      46\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.81      0.89      0.85       110\n",
      "    Survived       0.79      0.67      0.72        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.78      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Accuracy ---\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy * 100:.2f}%)\\n\")\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\"\"\n",
    "  - True Negatives  (correctly predicted died):          {cm[0][0]}\n",
    "  - False Positives (predicted survived, actually died): {cm[0][1]}\n",
    "  - False Negatives (predicted died, actually survived): {cm[1][0]}\n",
    "  - True Positives  (correctly predicted survived):      {cm[1][1]}\n",
    "\"\"\")\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Died', 'Survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-header",
   "metadata": {},
   "source": [
    "## 7. Compare: Before vs After\n",
    "\n",
    "| Aspect | Notebook 02 (Separate Steps) | Notebook 03 (Pipeline) |\n",
    "|---|---|---|\n",
    "| **Preprocessing** | Manual `fit_transform` + `transform` calls | Handled automatically inside the pipeline |\n",
    "| **Training** | `model.fit(X_train_processed, y_train)` | `pipeline.fit(X_train, y_train)` — takes raw data directly |\n",
    "| **Prediction** | Must remember to transform first, then predict | `pipeline.predict(X_test)` — one call does everything |\n",
    "| **Leakage risk** | Possible if you accidentally fit on test data | Prevented by design |\n",
    "| **Deployment** | Must save preprocessor and model separately | Save one pipeline object |\n",
    "\n",
    "The results (accuracy, confusion matrix, classification report) are **identical** — we didn't change the logic, just the structure. This is a **refactor**, not a new model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54xd2et8e88",
   "metadata": {},
   "source": [
    "## 8. Conclusion & Next Steps\n",
    "\n",
    "### What we achieved\n",
    "- Refactored separate preprocessing and model steps into a **single end-to-end Pipeline**\n",
    "- Confirmed that results are identical — this was a structural improvement, not a model change\n",
    "- The pipeline is now production-ready: one object handles everything from raw data to predictions\n",
    "\n",
    "### What's next\n",
    "- **Try different models** — swap `LogisticRegression` for Random Forest, SVM, or Gradient Boosting within the same pipeline structure\n",
    "- **Feature engineering** — create new features (e.g., family size from SibSp + Parch) to improve recall on the \"Survived\" class\n",
    "- **Hyperparameter tuning** — use GridSearchCV or RandomizedSearchCV with the pipeline to find optimal settings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
